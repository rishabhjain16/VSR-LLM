2025-05-07 01:18:20,148 - INFO - Starting training with 6862 training examples, 734 validation examples
2025-05-07 01:18:20,148 - INFO - Model: /home/rishabh/Desktop/Experiments/VSR-LLM/checkpoints/Llama-2-7b-hf
2025-05-07 01:18:20,148 - INFO - Epochs: 6, Batch size: 8, IPA granularity: word
2025-05-07 01:32:05,283 - INFO - Step 50: loss = 9.6820
2025-05-07 01:45:49,408 - INFO - Step 100: loss = 0.0714
2025-05-07 01:59:33,597 - INFO - Step 150: loss = 0.0313
2025-05-07 02:13:17,871 - INFO - Step 200: loss = 0.0238
2025-05-07 02:26:53,182 - INFO - Step 250: loss = 0.0185
2025-05-07 02:40:37,562 - INFO - Step 300: loss = 0.0156
2025-05-07 02:54:21,812 - INFO - Step 350: loss = 0.0146
2025-05-07 03:08:06,090 - INFO - Step 400: loss = 0.0135
2025-05-07 03:21:41,463 - INFO - Step 450: loss = 0.0112
2025-05-07 03:35:25,929 - INFO - Step 500: loss = 0.0083
2025-05-07 03:37:25,663 - INFO - Evaluation: eval_loss = 0.0207
2025-05-07 03:51:10,368 - INFO - Step 550: loss = 0.0087
2025-05-07 04:04:54,869 - INFO - Step 600: loss = 0.0080
2025-05-07 04:18:30,257 - INFO - Step 650: loss = 0.0086
2025-05-07 04:32:14,834 - INFO - Step 700: loss = 0.0050
2025-05-07 04:45:59,447 - INFO - Step 750: loss = 0.0053
2025-05-07 04:59:44,102 - INFO - Step 800: loss = 0.0049
2025-05-07 05:13:28,751 - INFO - Step 850: loss = 0.0046
2025-05-07 05:27:04,402 - INFO - Step 900: loss = 0.0033
2025-05-07 05:40:49,033 - INFO - Step 950: loss = 0.0028
2025-05-07 05:54:33,733 - INFO - Step 1000: loss = 0.0026
2025-05-07 05:56:33,483 - INFO - Evaluation: eval_loss = 0.0206
2025-05-07 06:10:18,276 - INFO - Step 1050: loss = 0.0028
2025-05-07 06:23:54,037 - INFO - Step 1100: loss = 0.0023
2025-05-07 06:37:38,780 - INFO - Step 1150: loss = 0.0019
2025-05-07 06:51:23,473 - INFO - Step 1200: loss = 0.0019
2025-05-07 07:05:08,116 - INFO - Step 1250: loss = 0.0020
